# SAFE-MEME
SAFE-MEME is a novel framework designed for the detection of fine-grained hate speech in memes. The framework consists of two distinct variants: (a) SAFE-MEME-QA, which employs a Q&amp;A approach, and (b) SAFE-MEME-H, which utilizes hierarchical classification to categorize memes into one of three classes: explicit, implicit, or benign.
